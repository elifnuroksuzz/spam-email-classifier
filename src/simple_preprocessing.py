"""
Spam E-posta SÄ±nÄ±flandÄ±rÄ±cÄ± - Basit Veri Ã–n Ä°ÅŸleme
HÄ±zlÄ± ve etkili metin Ã¶n iÅŸleme
"""

import pandas as pd
import numpy as np
import re
import string
import matplotlib.pyplot as plt
from sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer
import joblib

class SimpleTextPreprocessor:
    """
    Basit ve hÄ±zlÄ± metin Ã¶n iÅŸleyici
    """
    
    def __init__(self):
        # SMS kÄ±saltmalarÄ±
        self.abbreviations = {
            'u': 'you', 'ur': 'your', 'r': 'are', 'n': 'and',
            'txt': 'text', 'msg': 'message', 'pls': 'please',
            '2': 'to', '4': 'for', 'luv': 'love', 'wat': 'what'
        }
        print("âœ“ Basit Ã¶n iÅŸleyici hazÄ±rlandÄ±")
    
    def clean_text(self, text):
        """Temel metin temizleme"""
        if pd.isna(text):
            return ""
        
        # KÃ¼Ã§Ã¼k harf
        text = text.lower()
        
        # KÄ±saltmalarÄ± geniÅŸlet
        for abbr, full in self.abbreviations.items():
            text = re.sub(r'\b' + abbr + r'\b', full, text)
        
        # Noktalama ve sayÄ±larÄ± kaldÄ±r
        text = re.sub(r'[^a-zA-Z\s]', '', text)
        
        # Fazla boÅŸluklarÄ± temizle
        text = re.sub(r'\s+', ' ', text).strip()
        
        return text
    
    def add_features(self, df):
        """Basit Ã¶zellikler ekle"""
        df_copy = df.copy()
        
        # Temel Ã¶zellikler
        df_copy['length'] = df_copy['message'].str.len()
        df_copy['word_count'] = df_copy['message'].str.split().str.len()
        df_copy['exclamation_count'] = df_copy['message'].str.count('!')
        df_copy['uppercase_count'] = df_copy['message'].str.count(r'[A-Z]')
        df_copy['has_numbers'] = df_copy['message'].str.contains(r'\d').astype(int)
        
        return df_copy

def main():
    """Ana fonksiyon"""
    print("ğŸš€ BASÄ°T VERÄ° Ã–N Ä°ÅLEME")
    print("=" * 40)
    
    # 1. Veri yÃ¼kle
    print("1. Veri yÃ¼kleniyor...")
    df = pd.read_csv('data/processed/spam_dataset.csv')
    print(f"âœ“ {len(df)} Ã¶rnek yÃ¼klendi")
    
    # 2. Ã–n iÅŸleyici oluÅŸtur
    print("2. Ã–n iÅŸleyici hazÄ±rlanÄ±yor...")
    preprocessor = SimpleTextPreprocessor()
    
    # 3. Ã–zellikler ekle
    print("3. Ã–zellikler ekleniyor...")
    df = preprocessor.add_features(df)
    
    # 4. Metinleri temizle
    print("4. Metinler temizleniyor...")
    print("   Ä°ÅŸlenen Ã¶rnekler:")
    
    processed_messages = []
    for i, message in enumerate(df['message']):
        cleaned = preprocessor.clean_text(message)
        processed_messages.append(cleaned)
        
        # Ä°lk 3 Ã¶rneÄŸi gÃ¶ster
        if i < 3:
            print(f"   {i+1}. Orijinal: '{message[:50]}...'")
            print(f"      TemizlenmiÅŸ: '{cleaned[:50]}...'")
    
    df['processed_message'] = processed_messages
    
    # 5. Label'larÄ± sayÄ±sal hale getir
    print("5. Label'lar kodlanÄ±yor...")
    df['label_encoded'] = df['label'].map({'ham': 0, 'spam': 1})
    
    # 6. TF-IDF Ã¶zellik Ã§Ä±karÄ±mÄ±
    print("6. TF-IDF Ã¶zellikleri Ã§Ä±karÄ±lÄ±yor...")
    vectorizer = TfidfVectorizer(
        max_features=5000,
        stop_words='english',
        ngram_range=(1, 2),  # 1-gram ve 2-gram
        min_df=2,
        max_df=0.95
    )
    
    # TF-IDF fit et
    tfidf_features = vectorizer.fit_transform(df['processed_message'])
    print(f"âœ“ {tfidf_features.shape[1]} TF-IDF Ã¶zelliÄŸi Ã§Ä±karÄ±ldÄ±")
    
    # 7. SonuÃ§larÄ± kaydet
    print("7. Veriler kaydediliyor...")
    
    # Ä°ÅŸlenmiÅŸ DataFrame'i kaydet
    df.to_csv('data/processed/final_preprocessed_data.csv', index=False)
    
    # TF-IDF vectorizer'Ä± kaydet
    joblib.dump(vectorizer, 'models/tfidf_vectorizer.joblib')
    
    # TF-IDF features'larÄ± kaydet (numpy array olarak)
    np.save('data/processed/tfidf_features.npy', tfidf_features.toarray())
    
    # 8. Ã–zet istatistikler
    print("\nğŸ“Š Ã–ZET Ä°STATÄ°STÄ°KLER")
    print("=" * 30)
    print(f"Toplam Ã¶rnek sayÄ±sÄ±: {len(df)}")
    print(f"Ham mesaj sayÄ±sÄ±: {len(df[df['label'] == 'ham'])}")
    print(f"Spam mesaj sayÄ±sÄ±: {len(df[df['label'] == 'spam'])}")
    print(f"TF-IDF Ã¶zellik sayÄ±sÄ±: {tfidf_features.shape[1]}")
    
    # Ã–zellik istatistikleri
    print(f"\nÃ–zellik Ä°statistikleri:")
    numeric_features = ['length', 'word_count', 'exclamation_count', 'uppercase_count', 'has_numbers']
    for feature in numeric_features:
        ham_mean = df[df['label'] == 'ham'][feature].mean()
        spam_mean = df[df['label'] == 'spam'][feature].mean()
        print(f"{feature:20s} | Ham: {ham_mean:6.2f} | Spam: {spam_mean:6.2f}")
    
    # En Ã¶nemli TF-IDF Ã¶zellikleri
    print(f"\nEn YÃ¼ksek TF-IDF Skorlu Kelimeler:")
    feature_names = vectorizer.get_feature_names_out()
    tfidf_scores = np.mean(tfidf_features.toarray(), axis=0)
    top_indices = np.argsort(tfidf_scores)[-10:][::-1]
    
    for i, idx in enumerate(top_indices):
        print(f"{i+1:2d}. {feature_names[idx]:15s} ({tfidf_scores[idx]:.4f})")
    
    print(f"\nâœ… VERÄ° Ã–N Ä°ÅLEME TAMAMLANDI!")
    print(f"ğŸ“ Ä°ÅŸlenmiÅŸ veri: data/processed/final_preprocessed_data.csv")
    print(f"ğŸ”§ TF-IDF model: models/tfidf_vectorizer.joblib")
    print(f"ğŸ“Š TF-IDF Ã¶zellikler: data/processed/tfidf_features.npy")
    
    print(f"\nğŸ¯ Sonraki adÄ±m: Model eÄŸitimi ve deÄŸerlendirme")

if __name__ == "__main__":
    main()